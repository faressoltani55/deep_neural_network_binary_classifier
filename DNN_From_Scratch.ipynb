{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# In this notebook, I tried to implement and explain the implementation of a binary classification deep neural network."
      ],
      "metadata": {
        "id": "R98fqO2PDnIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "TIjEO3TUwVeH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the initial state of the neural network (default values of weights and biases):\n",
        "\n",
        "def initialize(dimensions): # Dimensions is an array containing the desired lengths of each layer\n",
        "  parameters = {}\n",
        "  layers = len(dimensions) # Number of layers\n",
        "\n",
        "  for layer in range(1, layers):\n",
        "    parameters[\"W\" + str(layer)] = np.random.randn(dimensions[layer], dimensions[layer-1]) # Matrix of weights of the layer \"layer\" 's neurons\n",
        "    parameters[\"b\" + str(layer)] = np.random.randn(dimensions[layer], 1) # Matrix of biases of the layer \"layer\" 's neurons\n",
        "  \n",
        "  return parameters"
      ],
      "metadata": {
        "id": "o_6PODe_x-cJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fEznmCFmwBTN"
      },
      "outputs": [],
      "source": [
        "# Forward Propagation:\n",
        "\n",
        "def forward_propagation(X, parameters):\n",
        "\n",
        "  activations = { \"A0\" : X }\n",
        "  layers = len(parameters) // 2 # Since the parameters dictionary contains both the Matrix of weights and array of biases for each layer\n",
        "  \n",
        "  for layer in range(1, layers + 10):\n",
        "    Z = parameters[\"W\" + str(layer)].dot(activations[\"A\" + str(layer - 1)]) + parameters[\"b\" + str(layer)]\n",
        "    activations[\"A\" + str(layer)] = 1 / (1 + np.exp(-Z))\n",
        "\n",
        "  return activations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Back Propagation\n",
        "\n",
        "def back_propagation(y, activations, parameters):\n",
        "  m = y.shape[1] # Number of \"y\"s we have\n",
        "  layers = len(parameters) // 2 # number of layers\n",
        "\n",
        "  dZ = activations[\"A\" + str(layers)] - y # We start from the last layer's activation\n",
        "\n",
        "  gradients = {} # \"dW\"s and \"db\"s\n",
        "\n",
        "  for layer in reversed(range(1, layers+ 1)):\n",
        "    gradients[\"dW\" + str(layer)] = 1/m * np.dot(dZ, activations[\"A\" + str(layer - 1)].T)\n",
        "    gradients[\"db\" + str(layer)] = 1/m * np.sum(dZ, axis=1, keepdims=True)\n",
        "    if layer > 1: # Because it doesn't make sense calculating dZ1 to be used by dW0 and db0 which don't exist\n",
        "      dZ = np.dot(parameters[\"W\" + str(layer)].T, dZ) * activations[\"A\" + str(layer - 1)] * (1 - activations[\"A\" + str(layer - 1)])\n",
        "\n",
        "  return gradients"
      ],
      "metadata": {
        "id": "lGGs3iPAxMos"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update weights and  biases:\n",
        "\n",
        "def update(parameters, gradients, lr): # lr is the learning rate\n",
        "  layers = len(parameters) // 2\n",
        "  for layer in range(1, layers + 1):\n",
        "    parameters[\"W\" + str(layer)] = parameters[\"W\" + str(layer)] - lr * gradients[\"dW\" + str(layer)]\n",
        "    parameters[\"b\" + str(layer)] = parameters[\"b\" + str(layer)] - lr * gradients[\"db\" + str(layer)]\n",
        "\n",
        "  return parameters"
      ],
      "metadata": {
        "id": "nRJ8sflk5yl4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log loss function to keep track of the loss:\n",
        "\n",
        "def log_loss(y, A):\n",
        "  m = y.shape[1]\n",
        "  return 1/m * np.sum(- y * np.log(A) - (1 - y) * np.log(1-A))"
      ],
      "metadata": {
        "id": "rJ3ikdD37Kfv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict function:\n",
        "\n",
        "def predict(X, parameters):\n",
        "  activations = forward_propagation(X, parameters)\n",
        "  Af = activations[\"A\" + str(len(parameters) // 2)]\n",
        "  return Af > 1"
      ],
      "metadata": {
        "id": "jvMXotjs8TRh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "def neural_network(X, y, dimensions, lr, n_iter):\n",
        "\n",
        "  parameters = initialize(dimensions)\n",
        "  layers = len(parameters) // 2\n",
        "\n",
        "  train_loss = []\n",
        "  train_acc = []\n",
        "  train_recall = []\n",
        "  train_precision = []\n",
        "  train_fscores = []\n",
        "\n",
        "  for epoch in range(n_iter):\n",
        "    activations = forward_propagation(X, parameters)\n",
        "    gradients = back_propagation(y, activations, parameters)\n",
        "    parameters = update(parameters, gradients, lr)\n",
        "\n",
        "    Af = activations[\"A\" + str(layers)]\n",
        "    y_pred = predict(X, parameters)\n",
        "\n",
        "    train_loss.append(log_loss(y, Af))\n",
        "    train_acc.append(accuracy_score(y, y_pred))\n",
        "    train_recall.appen(recall_score(y, y_pred))\n",
        "    train_precision.appen(precision_score(y, y_pred))\n",
        "    train_fscores.appen(f1_score(y, y_pred))\n",
        "\n",
        "  return (parameters, train_loss, train_acc, train_recall, train_precision, train_fscores)"
      ],
      "metadata": {
        "id": "wastoLH66hxM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your X, y dimensions, learning rate and number of epochs here:\n",
        "\n",
        "# Call the function neural_network"
      ],
      "metadata": {
        "id": "-yTEARPaCIMn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_metrics(train_loss, train_acc, train_recall, train_precision, train_fscores):\n",
        "  fig = plt.figure(figsize = (10,6))\n",
        "  plt.plot(train_loss)\n",
        "  plt.title('model Loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(train_acc)\n",
        "  plt.title('model Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(train_recall)\n",
        "  plt.title('model recall')\n",
        "  plt.ylabel('Recall')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(train_precision)\n",
        "  plt.title('model precision')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(train_fscores)\n",
        "  plt.title('model F-score')\n",
        "  plt.ylabel('F-Score')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "E6CBUWDyCvpF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BOrVXU5NDkEZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}